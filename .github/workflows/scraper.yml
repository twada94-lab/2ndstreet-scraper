name: Run 2ndStreet Scraper (CloudScraper Mode)

on:
  schedule:
    - cron: "0 */6 * * *" # 6時間おきに再起動
  workflow_dispatch: # 手動実行

jobs:
  run:
    runs-on: ubuntu-latest
    timeout-minutes: 350

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install cloudscraper beautifulsoup4 requests
          
          git config --local user.email "github-actions@github.com"
          git config --local user.name "github-actions"
          touch latest_count.txt

      - name: Run scraper loop
        env:
          DISCORD_WEBHOOK_URL: ${{ secrets.DISCORD_WEBHOOK_URL }}
        run: |
          end=$((SECONDS+21000)) # 約5時間50分稼働

          while [ $SECONDS -lt $end ]; do
            echo "--- Scraper Check: $(date) ---"
            
            # スクリプト実行
            python scraper_line.py || echo "Python failed, continuing..."

            # 変化があればGitHubへ保存
            if [ -f latest_count.txt ]; then
              git add latest_count.txt
              if ! git diff --cached --quiet; then
                git commit -m "Update count [bot]"
                git pull --rebase
                git push || echo "Push failed, will retry next turn."
              fi
            fi

            # 待機時間（まずは300秒=5分で安定性を確認してください）
            echo "Waiting 300 seconds..."
            sleep 300
          done
